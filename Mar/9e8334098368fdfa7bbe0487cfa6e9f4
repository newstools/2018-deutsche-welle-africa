We've been manipulating the way we want to see the world — and how we want others to see us in it — for almost as long as humans have been able to paint or take photos. "Look back through Hitler, Stalin, Mao or Castro, all of these people manipulated photos in an effort to change history," says Hany Farid, a professor of computer science at Dartmouth College in the United States. "States do, bad actors do it, criminals do it and hoaxers do it." And it's not only dictators and demons. Computer technology has been used to manipulate images, video and audio for legitimate purposes too — although some examples may be ethically ambiguous. The movie industry uses computer-generated imagery (CGI) to bring dead actors back to life, like Peter Cushing (Grand Moff Tarkin) in Star Wars "Rogue One," models are routinely photoshopped in advertising, and we've made an art of auto-tuning the vocals of professional singers who can't sing. Moving images are … moving Video manipulation is a special case. A fake video can be incredibly compelling because it's a moving image. Take the phenomenon of "deepfake celebrity porn" videos, which popped up on the social media platform Reddit at the end of 2017. Carrie Fischer will reportedly appear in "Star Wars: Episode IX" posthumously, but without CGI effects #ICYMI: Some dastardly individuals used a freely available software that deploys an artificial intelligence (AI) to paste the faces of known female actors like Emma Watson onto those of porn stars. The fakes were so good, technically speaking, that if you weren't paying proper attention (and who would be?), you may well have thought Watson had gone from feminist to freak — and you would have believed it. "The first we saw of this was people screwing around putting Nicholas Cage's face in all sorts of movies, and I think most people would say 'That's pretty harmless,' but you could see the trend," says Farid. "So the next thing people did was this awful, awful thing of taking famous people and not famous people and creating involuntary pornography. And here's how you know how bad this content is: Pornhub and Reddit said they didn't want it on their platforms. How bad do you have to be to be banned from Pornhub and Reddit?!" There's no doubt deepfakes are bad. But the technology is really good — good enough to trick our brains anyway. Read more: Reddit takes down subforum on deepfake porn videos From generics to fakes "There's a generic model of face that people have developed over time, and AI can be used in the form of deep learning networks to look at an image of a face and map it to a 3D model of that generic face," says Philipp Slusallek, a professor of computer graphics at Saarland University in south-western Germany and scientific director at the German Research Center for Artificial Intelligence. Basically, the AI superimposes one face onto another, including its facial gestures, speech or eye motion. "And that is essentially what is being used to create these deepfakes," says Slusallek. "The original face is just being animated in different ways. That's why it looks so convincing, because in some sense it is the original face of that original actor or person." And in some cases the image will override what you think you know. Even if you think you know a thing or two about Emma Watson — you may indeed follow her as an feminist activist and as a result consider her the last person to move into porn — that prior knowledge may still not be enough to help your brain spot the fake. Emma Watson (right) — in more innocent days — as Hermine in the Harry Potter series "We're living in a time when there's a widespread and systematic abuse [of technology] by different actors. They can generate synthetic faces, and people cannot tell the difference between the fake, which is generated by a deep neural network algorithm, and a real face," says Alexander Todorov, professor of psychology at Princeton University. Uncanny context When the software superimposes one person's dynamic facial expressions on to another it can be enough to let you believe what you see is true. "Facial movements are critical here, because what we see in these dynamic images are cues that suggest agency and a mind behind it," says Todorov, who has researched the power of faces and first impressions. "When it's done well, it's easy to fool people." You might think we should be better at telling the difference — and a theory called The Uncanny Valley suggests we are. It was proposed in 1970 by a Japanese roboticist called Masahiro Mori. The theory says that the more an object looks like a human the cuter it gets, but that there's this tipping point at which the image gets creepy. And if you get stuck on that, you fall into the valley. Empirical evidence of the Uncanny Valley is sketchy. But there is some anecdotal evidence to suggest it is true. "So they say creating compelling scenes will always be creepy because of CGI," says Christine E. Looser, a behavioral scientist at Minerva Schools in the US. "But the problem with these fakes is that it's not CGI. It's a minuscule amount of CGI in an otherwise compelling scene. So I would image you're probably paying a little bit of attention to the face but it's just kind of adding to the other things you might be looking at, and that's maybe why it doesn't feel viscerally creepy from the perceptual information." The dark side of democratization It almost sounds as though we want to be fooled. And all this has been made possible by a process known — ironically — as the democratization of technology. Actor Peter Cushing returned from the dead as a CGI recreation in Star Wars "Rogue One" You no longer need to understand how artificial intelligence machine learning works. All you need to do is download the software, feed it some video, and click a button, presumably labelled "be creepy." Hey presto. You've created a compelling piece of video that 20 odd years ago was the preserve of expert film editors. "We have taken the process of creating sophisticated fakes out of the hands of a relatively small number of highly skilled people and put it in the hands of an average redditor," says Farid. "The amount of power in these machine learning algorithms is made more or less freely available, and believing what we see, hear and read online is going to get pretty complicated." Farid says we've held onto video as a more trustworthy medium because of the sophistication that used to be required to manipulate it. But that's all changed. It's no longer a "big stretch of the imagination" to think we might start seeing fake videos of President Donald Trump talking about "launching nuclear weapons against North Korea." "Suddenly you can see very real threats," says Farid. The misuse of this technology worries Slusallek too — although he says the technology itself is "neutral" and that there's a lot of good that can be done with it. There's some talk of similar technology being used to create CGIs of dead relatives to help people in the grieving process or to help people with Asperger's who might benefit from communing with "familiar faces." "The thing that's changed," says Slusallek, "is that anyone can use this software now and it happens in real-time, so that makes it much easier to abuse." Technology vs. technology Technologists currently believe the best way to track and verify fakes, at least those made with an AI, is to use another AI. "Technology has always fought technology, weapons have always fought weapons, and biological agents have always fought other types of biological agents," says Farid. "That's part of the game." But now, he says, we're deploying "one blackbox technology that is not well understood to fight another blackbox technology that is not well understood." "And I'm a little uncomfortable with a blackbox where you shove data into it and out comes an answer "yes" / "no" — whether that's for detecting fakes, predicting whether someone is going to commit a crime in the future, determining whether your car should stop or not stop," he says. "From an engineering, scientific and even a philosophical perspective, it is good to understand how these things work." Read more: Conference debates how AI can shed its 'black box' image So what else can we do? First, Farid says we need to think seriously about the ways we consume digital content — of all the articles shared on Facebook, says Farid, 80 percent are shared by people who have only read the headline. So we need to take more responsibility for our own actions online. And second, the social media companies need to think hard about their own responsibilities too. "Half of Americans think there should be some regulation on big tech. That is a dramatic shift from just a year ago," says Farid. "It's gone from Silicon Valley can do no wrong to 'Oh my God, there are some real problems here,' and these companies are basically like the tobacco industry." At the beginning of the "Robots" exhibition in London's Science Museum, visitors first encounter a realistic reproduction of a human baby. Just like any newborn, this robot's activity is limited to involuntary arm and leg movements; it appears to be breathing and can sneeze. Such babies are now often made for film sets; they're so life-like that some people feel strong emotions towards them. The exhibition covers humanity's 500-year-long quest to reproduce their features in mechanized forms. Although the term "robot" wasn't used until 1920, mechanical characters have been created for centuries. These automata would reenact Bible stories, for example. This monk, driven by a key-wound spring, comes from Spain and possibly dates as early as 1560. In the 16th century, extraordinary clockwork-driven automata would find a home in aristocrats' cabinets of curiosities, or "Wunderkammern." The "Marvel" section of the exhibition features among others the legendary Silver Swan from 1773. When wound up, the swan moves, preens itself and catches a fish. Novelist Mark Twain once described the swan as having "a living intelligence in its eyes." Long before humanoid-figures were created, prosthetic devices were developed to replace lost limbs. An early model was found on an Egyptian mummy dating back to between 950-710 BC. For steampunk fans, these steel and brass Victorian-era prosthetic arms shown at the "Robots" exhibition may seem beautiful; others might find them rather sinister. In 1920, the Czech writer Karel Capek invented the word "robot" for his science fiction play "R.U.R.," which stands for "Rossum's Universal Robots." The term came from the Czech "robota," which means forced labor. The influential play was translated into 30 languages by 1923. In this picture, "Eric" (right) is a reproduction of one of the first robots in the world, originally from 1928. Fritz Lang's pioneering science-fiction work "Metropolis" (1927) featured one of the first robots of film history, the "Maschinenmensch" (machine-human). In this story set in 2026, the robot's creator aims to reproduce the woman he loved, Maria. A model of this iconic character is also on show at the exhibition. Our perception of robots has been greatly influenced by art. Already in Capek's play, robots rise up to overthrow their creators. Since then, movies have also contributed to their threatening image. One of the most iconic robots in film history was created by James Cameron in his 1984 thriller, "The Terminator." The T800 Terminator from "Terminator Genisys" is also part of the exhibition. The London exhibition has also planned discussions and screenings of films focusing on artificial intelligence, such as Steven Spielberg's "A.I. Artificial Intelligence" (2001) and Alex Garland's "Ex Machina" (2015). The latter stars Alicia Vikander as an extremely advanced robot (picture). Increasingly becoming part of our reality, the themes of such movies are no longer surreal science fiction. Increasingly, robots are used to replace humans in industrial jobs. Why should people be obliged to do tasks characterized by the "four Ds" - dumb, dull, dirty or dangerous - when a robot can perform them? It only takes a few minutes for a regular worker to "teach" Baxter the robot a new task. It is sold for $25,000 (23,000 euros) - about the average annual salary of a manual laborer. Sending out robots to clear dangerous landmines is clearly an advantage, but definitions of a "dull" job may vary. The Japanese Kodomoroid is a news-speaking android from 2014. She looks disturbingly human and can fluently report the news in a variety of languages, without stumbling. She is even programmed with a good sense of humor. Admittedly, she's a little stiff - for now. Rob Knight's open source android, ROSA, is the first "anthropomimetic" robot, which means that it reproduces the human body's structures. The robots shown at the exhibition at the Science Museum in London are not nearly as advanced as the androids of the TV series "Westworld," but they still provoke reflections on what it means to be human. The show runs from February 8 to September 3, 2017. Author: Elizabeth Grenier